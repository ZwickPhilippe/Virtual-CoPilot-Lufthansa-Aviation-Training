{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama_index llama-index-embeddings-huggingface llama-index-llms-huggingface streamlit python-dotenv python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:35:33.996292400Z",
     "start_time": "2024-12-06T10:35:30.467314Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage, SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import helpers.my_XML as myXML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:37:19.999435800Z",
     "start_time": "2024-12-06T10:37:07.363620100Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\") #dunzhang/stella_en_1.5B_v5\") #Snowflake/snowflake-arctic-embed-m-v1.5\")#\n",
    "local_llm = HuggingFaceLLM(\n",
    "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\", # \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    tokenizer_name=\"meta-llama/Llama-3.2-3B-Instruct\" # \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = local_llm\n",
    "\n",
    "model_names_for_path = \"_llama3B_bgeL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:35:09.183117900Z",
     "start_time": "2024-12-06T10:35:09.161533200Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"./_MANUALS/\"\n",
    "\n",
    "FCOM_path = base_path + \"XML_C_Ops_FCOM_A318_A319_A320_A321_21-Aug-2024_DLH/\"\n",
    "FCTM_path = base_path + \"FCTM_A320_PEGMA/\"\n",
    "FCM_path = base_path + \"FCM_PEGMA/\"\n",
    "CCC_path = base_path + \"CCC_Individual_Chunks/\"\n",
    "background_path = base_path + \"background/\"\n",
    "briefings_path = base_path + \"Briefing PPTs/\"\n",
    "\n",
    "index_storage_path = base_path + \"storage/\"\n",
    "\n",
    "print(f\"FCOM path: {FCOM_path}\")\n",
    "print(f\"FCTM path: {FCTM_path}\")\n",
    "print(f\"FCM path: {FCM_path}\")\n",
    "print(f\"CCC path: {CCC_path}\")\n",
    "print(f\"Background path: {background_path}\")\n",
    "print(f\"Briefings path: {briefings_path}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Index storage path: {index_storage_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your folder structure accordingly to the schema above or the one you choose. Otherwise you are going to run into errors below that folders are not found!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCOM_index = None\n",
    "index_store = index_storage_path + \"FCOM\" + model_names_for_path\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    FCOM_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not FCOM_index:\n",
    "    FCOM_index = myXML.create_index(FCOM_path + \"DATA/DU\",\n",
    "                                    myXML.parse_titles_bottom_up(FCOM_path + \"DATA/XML_N_FCOM_DLH_TF_N_EU__20240821.xml\"))\n",
    "    FCOM_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCTM_index = None\n",
    "index_store = index_storage_path + \"FCTM\" + model_names_for_path\n",
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    FCTM_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not FCTM_index:\n",
    "    FCTM_index = myXML.create_index(FCTM_path + \"DU\",\n",
    "                                    myXML.parse_titles_bottom_up_PEGMA(FCTM_path + \"document.xml\"))\n",
    "    FCTM_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCM_index = None\n",
    "index_store = index_storage_path + \"FCM\" + model_names_for_path\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    FCM_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not FCM_index:\n",
    "    FCTM_index = myXML.create_index(FCM_path + \"DU\",\n",
    "                                    myXML.parse_titles_bottom_up_PEGMA(FCM_path + \"document.xml\"))\n",
    "    FCTM_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LH Group Background Knowledge Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_index = None\n",
    "index_store = index_storage_path + \"background\" + model_names_for_path\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    background_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not background_index:\n",
    "    background_index = myXML.create_index(background_path + \"DU\",\n",
    "                                          myXML.parse_titles_bottom_up_PEGMA(background_path + \"document.xml\"))\n",
    "\n",
    "    background_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Conversion Course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC_index = None\n",
    "index_store = index_storage_path + \"CCC\" + model_names_for_path\n",
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    CCC_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not CCC_index:\n",
    "    ccc = SimpleDirectoryReader(\n",
    "        input_dir=CCC_path,\n",
    "        required_exts=[\".pdf\"],\n",
    "        recursive=False\n",
    "    ).load_data()\n",
    "\n",
    "    # we want filename used for embedding & llm response\n",
    "    for document in ccc:\n",
    "        if (\"file_name\" in document.excluded_embed_metadata_keys):\n",
    "            document.excluded_embed_metadata_keys.remove(\"file_name\")\n",
    "        if (\"file_name\" in document.excluded_llm_metadata_keys):\n",
    "            document.excluded_llm_metadata_keys.remove(\"file_name\")\n",
    "\n",
    "    # build index\n",
    "    CCC_index = VectorStoreIndex.from_documents(ccc, show_progress=True)\n",
    "\n",
    "    # persist index\n",
    "    CCC_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Briefing PPTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPT_index = None\n",
    "json_output_path = briefings_path + \"extracted_briefings.json\"\n",
    "json_chunks_path = briefings_path + \"chunks\"\n",
    "index_store = index_storage_path + \"briefings\" + model_names_for_path\n",
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    PPT_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not PPT_index:\n",
    "    myXML.process_pptx_files(briefings_path, json_output_path)\n",
    "    myXML.create_simple_chunks_for_briefings_json(\n",
    "        json_output_path, json_chunks_path)\n",
    "    print(f\"Extraction complete! Chunks saved to {json_chunks_path}\")\n",
    "\n",
    "    briefings_docs = SimpleDirectoryReader(\n",
    "        input_dir=json_chunks_path,\n",
    "        required_exts=[\".json\"],\n",
    "        recursive=False\n",
    "    ).load_data()\n",
    "    briefings_index = VectorStoreIndex.from_documents(\n",
    "        briefings_docs, show_progress=True)\n",
    "    briefings_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have test cases for FCOM, FCTM, FCM and LH Background Knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FCOM = pd.read_csv(\"tests/FCOM_test.csv\", dtype={\n",
    "                      'input': str, 'input_question': str, 'output_merged_duSol': str, 'output': str})\n",
    "df_FCTM = pd.read_csv(\"tests/FCTM_test.csv\", dtype={\n",
    "                      'input': str, 'input_question': str, 'output_merged_duSol': str, 'output': str})\n",
    "df_FCM = pd.read_csv(\"tests/FCM_test.csv\",\n",
    "                     dtype={'input': str, 'input_question': str, 'output': str})\n",
    "df_background = pd.read_csv(\"tests/background_test.csv\",\n",
    "                            dtype={'input': str, 'input_question': str, 'output': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [(df_FCOM, FCOM_index), (df_FCTM, FCTM_index), (df_FCM, FCM_index), (df_background, background_index)]:\n",
    "    print(\"-------------------\")\n",
    "    for k in [5, 25]:\n",
    "        retriever = m[1].as_retriever(similarity_top_k=k)\n",
    "        found_counter = 0\n",
    "        reciprocal_ranks = []\n",
    "\n",
    "        for index_store, row in m[0].iterrows():\n",
    "            input_value = row['input']\n",
    "            res = retriever.retrieve(input_value)\n",
    "\n",
    "            # Find if the correct output exists in the top-k results\n",
    "            found = False\n",
    "            for rank, snode in enumerate(res, start=1):\n",
    "                if row['output'] == (snode.node.id_)[:-4]:\n",
    "                    found_counter += 1\n",
    "                    reciprocal_ranks.append(1 / rank)\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                reciprocal_ranks.append(0)\n",
    "\n",
    "        # Calculate accuracy and MRR\n",
    "        print(\"k: \", k)\n",
    "        print(\"Accuracy:\", found_counter / len(m[0]))\n",
    "        print(\"MRR:\", sum(reciprocal_ranks) / len(m[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing of different tokenizer and embedding models can be done by simply changing the LLM/embedding model definition at the beginning or loading a different index accordingly.\n",
    "\n",
    "Below, we are showcasing the FCOM test that always merges a couple of XML (i.e. in the XLM structure we merge all duSol documents within the same duInv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCOM_merged_index = None\n",
    "index_store = index_storage_path + \"FCOM\" + model_names_for_path + \"_merged\"\n",
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=index_store\n",
    "    )\n",
    "    FCOM_merged_index = load_index_from_storage(storage_context)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if not FCOM_merged_index:\n",
    "    myXML.merge_all_duSol(XML_structure_path=FCOM_path + \"DATA/XML_N_FCOM_DLH_TF_N_EU__20240821.xml\",\n",
    "                          XML_folder_path=FCOM_path + \"DATA/DU\",\n",
    "                          output_folder=FCOM_path + \"DATA/DU_merged\")\n",
    "\n",
    "    FCOM_merged_index = myXML.create_index(FCOM_path + \"DATA/DU_merged\",\n",
    "                                           myXML.parse_titles_bottom_up_duInv(FCOM_path + \"DATA/XML_N_FCOM_DLH_TF_N_EU__20240821.xml\"))\n",
    "\n",
    "    FCOM_merged_index.storage_context.persist(persist_dir=index_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [(df_FCOM, FCOM_index)]:\n",
    "    print(\"-------------------\")\n",
    "    for k in [5, 25]:\n",
    "        retriever = m[1].as_retriever(similarity_top_k=k)\n",
    "        found_counter = 0\n",
    "        reciprocal_ranks = []\n",
    "\n",
    "        for index, row in m[0].iterrows():\n",
    "            input_value = row['input']\n",
    "            res = retriever.retrieve(input_value)\n",
    "\n",
    "            # Find if the correct output exists in the top-k results\n",
    "            found = False\n",
    "            for rank, snode in enumerate(res, start=1):\n",
    "                if row['output_merged_duSol'] == (snode.node.id_)[:-4]:\n",
    "                    found_counter += 1\n",
    "                    reciprocal_ranks.append(1 / rank)\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                reciprocal_ranks.append(0)\n",
    "\n",
    "        # Calculate accuracy and MRR\n",
    "        print(\"k: \", k)\n",
    "        print(\"Accuracy:\", found_counter / len(m[0]))\n",
    "        print(\"MRR:\", sum(reciprocal_ranks) / len(m[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
